{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1117b4c8",
   "metadata": {},
   "source": [
    "# Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62a5e917",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.6.1-cp311-cp311-macosx_10_9_x86_64.whl.metadata (31 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in ./.conda/lib/python3.11/site-packages (from scikit-learn) (2.2.5)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn)\n",
      "  Downloading scipy-1.15.3-cp311-cp311-macosx_14_0_x86_64.whl.metadata (61 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Downloading joblib-1.5.0-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading scikit_learn-1.6.1-cp311-cp311-macosx_10_9_x86_64.whl (12.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.5.0-py3-none-any.whl (307 kB)\n",
      "Downloading scipy-1.15.3-cp311-cp311-macosx_14_0_x86_64.whl (25.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m25.2/25.2 MB\u001b[0m \u001b[31m36.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4/4\u001b[0m [scikit-learn][0m [scikit-learn]\n",
      "\u001b[1A\u001b[2KSuccessfully installed joblib-1.5.0 scikit-learn-1.6.1 scipy-1.15.3 threadpoolctl-3.6.0\n",
      "Requirement already satisfied: pandas in ./.conda/lib/python3.11/site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.23.2 in ./.conda/lib/python3.11/site-packages (from pandas) (2.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.conda/lib/python3.11/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.conda/lib/python3.11/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.conda/lib/python3.11/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in ./.conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: numpy in ./.conda/lib/python3.11/site-packages (2.2.5)\n",
      "Requirement already satisfied: matplotlib in ./.conda/lib/python3.11/site-packages (3.10.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./.conda/lib/python3.11/site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in ./.conda/lib/python3.11/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./.conda/lib/python3.11/site-packages (from matplotlib) (4.58.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./.conda/lib/python3.11/site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: numpy>=1.23 in ./.conda/lib/python3.11/site-packages (from matplotlib) (2.2.5)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.conda/lib/python3.11/site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in ./.conda/lib/python3.11/site-packages (from matplotlib) (11.2.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./.conda/lib/python3.11/site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./.conda/lib/python3.11/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in ./.conda/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn\n",
    "!pip install pandas\n",
    "!pip install numpy\n",
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "96e0e079",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nbformat\n",
      "  Downloading nbformat-5.10.4-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting fastjsonschema>=2.15 (from nbformat)\n",
      "  Downloading fastjsonschema-2.21.1-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting jsonschema>=2.6 (from nbformat)\n",
      "  Using cached jsonschema-4.23.0-py3-none-any.whl.metadata (7.9 kB)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in ./.conda/lib/python3.11/site-packages (from nbformat) (5.7.2)\n",
      "Requirement already satisfied: traitlets>=5.1 in ./.conda/lib/python3.11/site-packages (from nbformat) (5.14.3)\n",
      "Collecting attrs>=22.2.0 (from jsonschema>=2.6->nbformat)\n",
      "  Using cached attrs-25.3.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema>=2.6->nbformat)\n",
      "  Using cached jsonschema_specifications-2025.4.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting referencing>=0.28.4 (from jsonschema>=2.6->nbformat)\n",
      "  Using cached referencing-0.36.2-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting rpds-py>=0.7.1 (from jsonschema>=2.6->nbformat)\n",
      "  Downloading rpds_py-0.24.0-cp311-cp311-macosx_10_12_x86_64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: platformdirs>=2.5 in ./.conda/lib/python3.11/site-packages (from jupyter-core!=5.0.*,>=4.12->nbformat) (4.3.8)\n",
      "Requirement already satisfied: typing-extensions>=4.4.0 in ./.conda/lib/python3.11/site-packages (from referencing>=0.28.4->jsonschema>=2.6->nbformat) (4.13.2)\n",
      "Downloading nbformat-5.10.4-py3-none-any.whl (78 kB)\n",
      "Downloading fastjsonschema-2.21.1-py3-none-any.whl (23 kB)\n",
      "Using cached jsonschema-4.23.0-py3-none-any.whl (88 kB)\n",
      "Using cached attrs-25.3.0-py3-none-any.whl (63 kB)\n",
      "Using cached jsonschema_specifications-2025.4.1-py3-none-any.whl (18 kB)\n",
      "Using cached referencing-0.36.2-py3-none-any.whl (26 kB)\n",
      "Downloading rpds_py-0.24.0-cp311-cp311-macosx_10_12_x86_64.whl (377 kB)\n",
      "Installing collected packages: fastjsonschema, rpds-py, attrs, referencing, jsonschema-specifications, jsonschema, nbformat\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7/7\u001b[0m [nbformat]5/7\u001b[0m [jsonschema]\n",
      "\u001b[1A\u001b[2KSuccessfully installed attrs-25.3.0 fastjsonschema-2.21.1 jsonschema-4.23.0 jsonschema-specifications-2025.4.1 nbformat-5.10.4 referencing-0.36.2 rpds-py-0.24.0\n"
     ]
    }
   ],
   "source": [
    "!pip install nbformat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72c698ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import time\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ef405489",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from tensorflow.keras import layers, models\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9cb0518",
   "metadata": {},
   "source": [
    "# Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "11835268",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"# Data Loader\\n\\nimport numpy as np\\nimport pandas as pd\\nimport pickle\\nimport os\\n\\n\\nclass Bunch(dict):\\n    def __init__(self, **kwargs):\\n        super().__init__(kwargs)\\n\\n        for key, value in kwargs.items():\\n            setattr(self, key, value)\\n\\ndef _convert_to_numpy_array(dataframes: list[pd.DataFrame], target: pd.Series):\\n    \\n    numpy_data = []\\n    for df in dataframes:\\n        numpy_data.append(df.values)\\n\\n    return np.array(numpy_data), target.to_numpy()\\n        \\ndef load_tsa_data(return_X_y=False):\\n\\n    with open('tsa_dataset/description.txt', 'r') as fdescr:\\n        descr = fdescr.read()\\n\\n    data_filename = os.path.join('tsa_dataset/data', 'tsa_data.pkl')\\n    with open(data_filename, 'rb') as file:\\n        data, target = pickle.load(file) # returns tuple[list[pd.Dataframe], pd.Series]\\n\\n    feature_names = data[0].columns.to_list() # list[str]\\n    target_names = ['stable', 'unstable']\\n\\n    data, target = _convert_to_numpy_array(data, target)\\n\\n    if return_X_y:\\n        return data, target\\n\\n    return Bunch(\\n        data=data,\\n        target=target,\\n        feature_names=feature_names,\\n        target_names=target_names,\\n        DESCR=descr,\\n        filename=data_filename\\n    )\",\n",
       " 'bunch = load_tsa_data()\\n\\n# print(bunch.DESCR)\\n# print(bunch.filename)\\n# print(bunch.data[:3])\\n# print(bunch.target[:3])\\n# print(bunch.feature_names)\\n# print(bunch.target_names)',\n",
       " 'data, target = bunch.data, bunch.target']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nbformat\n",
    "\n",
    "# Load the second uploaded notebook\n",
    "\n",
    "# Load the second uploaded notebook\n",
    "with open(notebook_path_2, 'r', encoding='utf-8') as f:\n",
    "    notebook_2 = nbformat.read(f, as_version=4)\n",
    "\n",
    "# Extract code cells from the second notebook\n",
    "code_cells_2 = [cell['source'] for cell in notebook_2.cells if cell.cell_type == 'code']\n",
    "code_cells_2[:3]  # Show first few code cells to understand the structure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "db308be5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_tsa_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m bunch = \u001b[43mload_tsa_data\u001b[49m()\n\u001b[32m      2\u001b[39m data, target = bunch.data, bunch.target\n",
      "\u001b[31mNameError\u001b[39m: name 'load_tsa_data' is not defined"
     ]
    }
   ],
   "source": [
    "bunch = load_tsa_data()\n",
    "data, target = bunch.data, bunch.target\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8735e23",
   "metadata": {},
   "source": [
    "\n",
    "# Scaling Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ced5d419",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# Assuming `data` and `target` are already defined in the notebook\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# If not, you need to define them based on your dataset\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# Example: data, target = some_data_loading_function()\u001b[39;00m\n\u001b[32m     14\u001b[39m \n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# Split data once to reuse the same test set\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m X_train_full, X_test, y_train_full, y_test = train_test_split(\u001b[43mdata\u001b[49m, target, test_size=\u001b[32m0.2\u001b[39m, random_state=\u001b[32m42\u001b[39m)\n\u001b[32m     18\u001b[39m fractions = [\u001b[32m0.1\u001b[39m, \u001b[32m0.25\u001b[39m, \u001b[32m0.5\u001b[39m, \u001b[32m0.75\u001b[39m, \u001b[32m1.0\u001b[39m]\n\u001b[32m     19\u001b[39m results = []\n",
      "\u001b[31mNameError\u001b[39m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Scaling Test (Data Size Only)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming `data` and `target` are already defined in the notebook\n",
    "# If not, you need to define them based on your dataset\n",
    "# Example: data, target = some_data_loading_function()\n",
    "\n",
    "# Split data once to reuse the same test set\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(data, target, test_size=0.2, random_state=42)\n",
    "\n",
    "fractions = [0.1, 0.25, 0.5, 0.75, 1.0]\n",
    "results = []\n",
    "\n",
    "for frac in fractions:\n",
    "    size = int(len(X_train_full) * frac)\n",
    "    X_train = X_train_full[:size]\n",
    "    y_train = y_train_full[:size]\n",
    "\n",
    "    clf = MLPClassifier(hidden_layer_sizes=(100,), max_iter=200, random_state=42)\n",
    "\n",
    "    start_time = time.time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    duration = time.time() - start_time\n",
    "\n",
    "    y_pred = clf.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    results.append((frac, size, duration, acc))\n",
    "    print(f\"Data Fraction: {frac:.2f}, Train Size: {size}, Time: {duration:.2f}s, Accuracy: {acc:.4f}\")\n",
    "\n",
    "# Results\n",
    "df_results = pd.DataFrame(results, columns=[\"Fraction\", \"Train Size\", \"Time (s)\", \"Accuracy\"])\n",
    "\n",
    "# Plot\n",
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "color = 'tab:blue'\n",
    "ax1.set_xlabel('Training Size')\n",
    "ax1.set_ylabel('Training Time (s)', color=color)\n",
    "ax1.plot(df_results[\"Train Size\"], df_results[\"Time (s)\"], marker='o', color=color)\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "ax1.grid(True)\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "color = 'tab:green'\n",
    "ax2.set_ylabel('Accuracy', color=color)\n",
    "ax2.plot(df_results[\"Train Size\"], df_results[\"Accuracy\"], marker='o', color=color)\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.title(\"Scaling Test: MLP Training Time & Accuracy\")\n",
    "plt.show()\n",
    "\n",
    "df_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e724d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display results as DataFrame\n",
    "df_results = pd.DataFrame(results, columns=[\"Fraction\", \"Train Size\", \"Time (s)\", \"Accuracy\"])\n",
    "print(df_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09fd7946",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "df_results.plot(x=\"Train Size\", y=[\"Time (s)\", \"Accuracy\"], marker='o', title=\"Scaling Test Results\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
